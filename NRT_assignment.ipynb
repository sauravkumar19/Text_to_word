{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1abbWY3TYQg59Bp2VPlAYYm9EzM-ZpgD-",
      "authorship_tag": "ABX9TyMb0c3KJx9FaZZ97jL9n/sQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sauravkumar19/Text_to_word/blob/main/NRT_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz8kX6TLnqls",
        "outputId": "0594ee99-4170-4a16-eaca-0129f04b8234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Define the output directory where you'll save the generated images and labels.\n",
        "output_dir = \"synthetic_data_with_orientation\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Define a dictionary mapping number words to numerical values.\n",
        "number_dict = {\n",
        "    'zero':0,'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5,\n",
        "    'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10,\n",
        "    'eleven': 11, 'twelve': 12, 'thirteen': 13, 'fourteen': 14, 'fifteen': 15,\n",
        "    'sixteen': 16, 'seventeen': 17, 'eighteen': 18, 'nineteen': 19, 'twenty': 20,\n",
        "    'twenty-one': 21, 'twenty-two': 22, 'twenty-three': 23, 'twenty-four': 24, 'twenty-five': 25,\n",
        "    'twenty-six': 26, 'twenty-seven': 27, 'twenty-eight': 28, 'twenty-nine': 29, 'thirty': 30,\n",
        "    'thirty-one': 31, 'thirty-two': 32, 'thirty-three': 33, 'thirty-four': 34, 'thirty-five': 35,\n",
        "    'thirty-six': 36, 'thirty-seven': 37, 'thirty-eight': 38, 'thirty-nine': 39, 'forty': 40,\n",
        "    'forty-one': 41, 'forty-two': 42, 'forty-three': 43, 'forty-four': 44, 'forty-five': 45,\n",
        "    'forty-six': 46, 'forty-seven': 47, 'forty-eight': 48, 'forty-nine': 49, 'fifty': 50,\n",
        "    'fifty-one': 51, 'fifty-two': 52, 'fifty-three': 53, 'fifty-four': 54, 'fifty-five': 55,\n",
        "    'fifty-six': 56, 'fifty-seven': 57, 'fifty-eight': 58, 'fifty-nine': 59, 'sixty': 60,\n",
        "    'sixty-one': 61, 'sixty-two': 62, 'sixty-three': 63, 'sixty-four': 64, 'sixty-five': 65,\n",
        "    'sixty-six': 66, 'sixty-seven': 67, 'sixty-eight': 68, 'sixty-nine': 69, 'seventy': 70,\n",
        "    'seventy-one': 71, 'seventy-two': 72, 'seventy-three': 73, 'seventy-four': 74, 'seventy-five': 75,\n",
        "    'seventy-six': 76, 'seventy-seven': 77, 'seventy-eight': 78, 'seventy-nine': 79, 'eighty': 80,\n",
        "    'eighty-one': 81, 'eighty-two': 82, 'eighty-three': 83, 'eighty-four': 84, 'eighty-five': 85,\n",
        "    'eighty-six': 86, 'eighty-seven': 87, 'eighty-eight': 88, 'eighty-nine': 89, 'ninety': 90,\n",
        "    'ninety-one': 91, 'ninety-two': 92, 'ninety-three': 93, 'ninety-four': 94, 'ninety-five': 95,\n",
        "    'ninety-six': 96, 'ninety-seven': 97, 'ninety-eight': 98, 'ninety-nine': 99, 'hundred': 100\n",
        "}\n",
        "\n",
        "# Define a list of possible text orientations.\n",
        "text_orientations = ['normal', 'UPPERCASE', 'MixedCase', 'miXedCaSe', 'rAnDoM CaSe']\n",
        "\n",
        "# Set the desired number of data points.\n",
        "num_data_points = 100000\n",
        "\n",
        "for i in range(num_data_points):\n",
        "    # Choose a random number word.\n",
        "    word = random.choice(list(number_dict.keys()))\n",
        "\n",
        "    # Get the corresponding numerical value from the dictionary.\n",
        "    label = number_dict[word]\n",
        "\n",
        "    # Choose a random text orientation.\n",
        "    orientation = random.choice(text_orientations)\n",
        "\n",
        "    # Create a blank image with a white background.\n",
        "    image = np.ones((100, 200, 3), dtype=np.uint8) * 255\n",
        "    cv2.rectangle(image, (0, 0), (200, 100), (255, 255, 255), -1)  # White background\n",
        "\n",
        "    # Choose a random color for the text.\n",
        "    text_color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
        "\n",
        "    # Define the font and text size.\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    base_font_scale = 1.5\n",
        "    font_thickness = 2\n",
        "    spacing = int(200/(len(word)*1.5))\n",
        "    new_x = 10\n",
        "    new_y = 50\n",
        "\n",
        "    # Apply the selected text orientation\n",
        "    if orientation == 'UPPERCASE':\n",
        "        word = word.upper()\n",
        "    elif orientation == 'MixedCase':\n",
        "        word = word.title()\n",
        "    elif orientation == 'miXedCaSe':\n",
        "        word = ''.join([c.upper() if i % 2 == 0 else c.lower() for i, c in enumerate(word)])\n",
        "    elif orientation == 'rAnDoM CaSe':\n",
        "        word = ''.join([c.upper() if random.choice([True, False]) else c.lower() for c in word])\n",
        "\n",
        "    # Calculate the position to center the text.\n",
        "    text_size = cv2.getTextSize(word, font, base_font_scale, font_thickness)[0]\n",
        "    x = (image.shape[1] - text_size[0]) // 2\n",
        "    y = (image.shape[0] + text_size[1]) // 2\n",
        "\n",
        "    # Generate a random angle for text rotation (in degrees)\n",
        "    rotation_angle = random.randint(0,360)\n",
        "\n",
        "     # Generate random scaling factors for each character in the word\n",
        "    char_scales = [random.uniform(0.6, 1.4) for _ in word]\n",
        "\n",
        "    # Generate random spacing between words\n",
        "    word_spacing = random.randint(0,3)  # Adjust as needed\n",
        "\n",
        "    for char, char_scale in zip(word, char_scales):\n",
        "        char_font_scale = base_font_scale * char_scale\n",
        "        char_size = cv2.getTextSize(char, font, char_font_scale, font_thickness)[0]\n",
        "\n",
        "\n",
        "        # Draw the rotated character on the image\n",
        "        cv2.putText(image, char, (new_x, new_y), font, char_font_scale, text_color, font_thickness, lineType=cv2.LINE_AA)\n",
        "\n",
        "        # Add spacing between characters within the word\n",
        "        new_x = new_x + spacing+word_spacing\n",
        "\n",
        "    center = (x + text_size[0] // 2, y - text_size[1] // 2)\n",
        "    rotation_matrix = cv2.getRotationMatrix2D(center, rotation_angle, 1)\n",
        "\n",
        "    # Rotate the blank image\n",
        "    rotated_image = cv2.warpAffine(image, rotation_matrix, (100, 200))\n",
        "\n",
        "\n",
        "\n",
        "    # Save the image.\n",
        "    image_filename = os.path.join(output_dir, f\"{i}.png\")\n",
        "    cv2.imwrite(image_filename, image)\n",
        "\n",
        "    # Create a label file (e.g., a text file) with the corresponding label.\n",
        "    label_filename = os.path.join(output_dir, f\"{i}.txt\")\n",
        "    with open(label_filename, \"w\") as label_file:\n",
        "        label_file.write(str(label))\n",
        "\n",
        "print(f\"Generated {num_data_points} synthetic images with orientation and labels in the '{output_dir}' directory.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc06Z2vgrroX",
        "outputId": "d9e48e8d-5c0d-4ce6-9a57-912192b3e1ce"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 100000 synthetic images with orientation and labels in the 'synthetic_data_with_orientation' directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1HzpLdXTS4Pp",
        "outputId": "18b8d849-d2c6-4f5d-942e-6e7ea9e7f424"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fIFtY-eIght'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "QfrqQvPknIql"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define the path to the directory containing the synthetic data and labels\n",
        "data_dir = \"synthetic_data_with_orientation\"\n",
        "\n",
        "# Initialize empty lists to store images and corresponding labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Loop through the image files in the data directory\n",
        "for filename in os.listdir(data_dir):\n",
        "    if filename.endswith(\".png\"):\n",
        "        # Load and preprocess the image\n",
        "        image = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
        "        image = cv2.resize(image, (28, 28))  # Resize the image to a common size (adjust as needed)\n",
        "\n",
        "        # Extract the label from the corresponding label file\n",
        "        label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "        label_filepath = os.path.join(data_dir, label_filename)\n",
        "        with open(label_filepath, \"r\") as label_file:\n",
        "            label = int(label_file.read().strip())\n",
        "\n",
        "        # Append the image and label to the lists\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "Cvutq88L5VsM"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(cv2.resize(images[1],(400,100)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "slOaizNlv--n",
        "outputId": "0e2d0340-fa28-4f63-f5eb-df33b8eea292"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=400x100>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFnrK2w0xhLi",
        "outputId": "23bc73d3-23c8-4c15-9efe-50fccb6afde8"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize pixel values to a range of [0, 1]\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Define the CNN model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(101, activation='softmax')  # 101 classes (0 to 100)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Reshape the input data to include the number of color channels (1 for grayscale)\n",
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Calculate accuracy and print classification report\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xEuoM5i1Kp3",
        "outputId": "4f250a51-add2-4ea1-ad54-4f8ff5339882"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2250/2250 [==============================] - 111s 49ms/step - loss: 2.1041 - accuracy: 0.4806 - val_loss: 0.5377 - val_accuracy: 0.8440\n",
            "Epoch 2/10\n",
            "2250/2250 [==============================] - 107s 47ms/step - loss: 0.3348 - accuracy: 0.9065 - val_loss: 0.2477 - val_accuracy: 0.9226\n",
            "Epoch 3/10\n",
            "2250/2250 [==============================] - 110s 49ms/step - loss: 0.1563 - accuracy: 0.9588 - val_loss: 0.1601 - val_accuracy: 0.9549\n",
            "Epoch 4/10\n",
            "2250/2250 [==============================] - 105s 47ms/step - loss: 0.1020 - accuracy: 0.9728 - val_loss: 0.0976 - val_accuracy: 0.9732\n",
            "Epoch 5/10\n",
            "2250/2250 [==============================] - 107s 47ms/step - loss: 0.0735 - accuracy: 0.9804 - val_loss: 0.1064 - val_accuracy: 0.9722\n",
            "Epoch 6/10\n",
            "2250/2250 [==============================] - 111s 49ms/step - loss: 0.0555 - accuracy: 0.9854 - val_loss: 0.0512 - val_accuracy: 0.9874\n",
            "Epoch 7/10\n",
            "2250/2250 [==============================] - 104s 46ms/step - loss: 0.0442 - accuracy: 0.9887 - val_loss: 0.0537 - val_accuracy: 0.9880\n",
            "Epoch 8/10\n",
            "2250/2250 [==============================] - 107s 47ms/step - loss: 0.0430 - accuracy: 0.9886 - val_loss: 0.0438 - val_accuracy: 0.9891\n",
            "Epoch 9/10\n",
            "2250/2250 [==============================] - 108s 48ms/step - loss: 0.0327 - accuracy: 0.9917 - val_loss: 0.0558 - val_accuracy: 0.9866\n",
            "Epoch 10/10\n",
            "2250/2250 [==============================] - 107s 48ms/step - loss: 0.0261 - accuracy: 0.9933 - val_loss: 0.0474 - val_accuracy: 0.9876\n",
            "625/625 [==============================] - 9s 14ms/step\n",
            "Accuracy: 0.98875\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       218\n",
            "           1       1.00      1.00      1.00       219\n",
            "           2       0.99      1.00      1.00       197\n",
            "           3       0.99      1.00      0.99       181\n",
            "           4       0.99      1.00      1.00       194\n",
            "           5       1.00      1.00      1.00       192\n",
            "           6       0.99      1.00      1.00       188\n",
            "           7       0.99      1.00      1.00       187\n",
            "           8       1.00      1.00      1.00       201\n",
            "           9       1.00      1.00      1.00       218\n",
            "          10       1.00      1.00      1.00       185\n",
            "          11       1.00      1.00      1.00       212\n",
            "          12       1.00      1.00      1.00       190\n",
            "          13       0.99      1.00      1.00       187\n",
            "          14       1.00      1.00      1.00       184\n",
            "          15       1.00      1.00      1.00       221\n",
            "          16       1.00      0.99      1.00       198\n",
            "          17       1.00      0.99      0.99       196\n",
            "          18       0.98      1.00      0.99       186\n",
            "          19       1.00      0.99      0.99       172\n",
            "          20       1.00      0.99      1.00       193\n",
            "          21       1.00      0.98      0.99       194\n",
            "          22       0.99      0.99      0.99       212\n",
            "          23       0.96      0.99      0.98       176\n",
            "          24       1.00      0.99      0.99       201\n",
            "          25       1.00      0.99      0.99       212\n",
            "          26       1.00      1.00      1.00       211\n",
            "          27       0.99      0.98      0.99       194\n",
            "          28       0.98      1.00      0.99       202\n",
            "          29       0.97      1.00      0.99       202\n",
            "          30       1.00      1.00      1.00       190\n",
            "          31       1.00      0.97      0.99       191\n",
            "          32       0.99      0.99      0.99       233\n",
            "          33       1.00      0.97      0.99       192\n",
            "          34       0.99      0.99      0.99       185\n",
            "          35       0.98      1.00      0.99       203\n",
            "          36       0.97      1.00      0.98       185\n",
            "          37       1.00      0.97      0.99       213\n",
            "          38       0.97      0.98      0.98       192\n",
            "          39       0.98      0.99      0.99       184\n",
            "          40       1.00      1.00      1.00       204\n",
            "          41       0.99      1.00      1.00       200\n",
            "          42       0.99      0.99      0.99       167\n",
            "          43       1.00      0.99      1.00       197\n",
            "          44       1.00      1.00      1.00       204\n",
            "          45       1.00      0.98      0.99       200\n",
            "          46       1.00      1.00      1.00       201\n",
            "          47       0.98      1.00      0.99       244\n",
            "          48       0.99      0.98      0.99       194\n",
            "          49       0.98      1.00      0.99       215\n",
            "          50       1.00      1.00      1.00       200\n",
            "          51       0.99      0.99      0.99       172\n",
            "          52       0.97      1.00      0.98       194\n",
            "          53       1.00      1.00      1.00       212\n",
            "          54       1.00      1.00      1.00       206\n",
            "          55       1.00      0.94      0.97       199\n",
            "          56       1.00      1.00      1.00       211\n",
            "          57       1.00      0.99      0.99       200\n",
            "          58       0.98      1.00      0.99       216\n",
            "          59       0.97      1.00      0.98       196\n",
            "          60       1.00      1.00      1.00       206\n",
            "          61       0.99      1.00      1.00       193\n",
            "          62       1.00      0.99      0.99       225\n",
            "          63       1.00      0.99      1.00       202\n",
            "          64       1.00      0.99      1.00       189\n",
            "          65       1.00      0.97      0.98       188\n",
            "          66       1.00      0.99      1.00       174\n",
            "          67       1.00      0.97      0.99       182\n",
            "          68       1.00      0.99      1.00       188\n",
            "          69       0.96      1.00      0.98       185\n",
            "          70       0.99      1.00      1.00       204\n",
            "          71       1.00      0.81      0.89       200\n",
            "          72       0.93      0.91      0.92       192\n",
            "          73       0.95      0.98      0.96       221\n",
            "          74       0.97      0.98      0.97       208\n",
            "          75       0.85      1.00      0.92       226\n",
            "          76       0.93      0.99      0.96       198\n",
            "          77       0.99      0.98      0.99       199\n",
            "          78       1.00      0.99      1.00       206\n",
            "          79       0.97      0.88      0.92       193\n",
            "          80       1.00      1.00      1.00       199\n",
            "          81       0.99      1.00      0.99       203\n",
            "          82       0.98      0.99      0.99       193\n",
            "          83       1.00      0.99      1.00       209\n",
            "          84       1.00      1.00      1.00       216\n",
            "          85       0.98      1.00      0.99       212\n",
            "          86       1.00      1.00      1.00       205\n",
            "          87       1.00      0.99      0.99       173\n",
            "          88       0.98      0.98      0.98       170\n",
            "          89       1.00      0.99      0.99       197\n",
            "          90       1.00      1.00      1.00       202\n",
            "          91       1.00      0.99      0.99       178\n",
            "          92       0.99      0.98      0.99       167\n",
            "          93       0.99      0.99      0.99       175\n",
            "          94       1.00      1.00      1.00       195\n",
            "          95       1.00      1.00      1.00       203\n",
            "          96       0.99      1.00      1.00       177\n",
            "          97       0.99      1.00      0.99       203\n",
            "          98       1.00      0.96      0.98       220\n",
            "          99       1.00      0.98      0.99       216\n",
            "         100       1.00      0.99      1.00       185\n",
            "\n",
            "    accuracy                           0.99     20000\n",
            "   macro avg       0.99      0.99      0.99     20000\n",
            "weighted avg       0.99      0.99      0.99     20000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = cv2.imread('/content/drive/MyDrive/ProjectA/IMG20230917122900 (1).jpg', cv2.IMREAD_GRAYSCALE)\n",
        "a = image = cv2.resize(image, (28, 28))"
      ],
      "metadata": {
        "id": "FRWjRsYJ9lwj"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "X8IHcUFU90-e",
        "outputId": "16a2e863-56af-415a-b86b-3f4d7b2af951"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABC0lEQVR4nNWSr0sDcRjGP9+7KZvOYBb/AsFu8Y8wCFpEEE1iuoO7A4dsZUtDLaYJCraBUTCLYBAMZ9CsQVhwshu67x6Dm94FLQbxaS8f3uf9acT3cn5gv4cRfBXfAR+AHEA3b6xrfKgBkKQyD9mGCAICAJ7XhiY5iFmFWXyYBNi3j6MBBxsfmYu8wPJ1pUqVY5jYmumXGBvYjjcvgBPH0uIGVpgrL7A0bOhyCiCEeYo+sP7aJKwBSHG7rkheR57UU0+664SeJMkBigkwXQIeXNxbksII9nMJLWDTOYc60Hg6Ij+YSnrTva6ks8apPEna60q7fUlCacWZKAvDLJNJH9u62auYv/uEfwLfAeZbm2/kfv+rAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = a/255.0"
      ],
      "metadata": {
        "id": "d5jrZ6uV9_8N"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = a.reshape(-1, 28, 28, 1)"
      ],
      "metadata": {
        "id": "2ZN2Chta-lyo"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CJFpy7Z-zwa",
        "outputId": "a816be22-7acd-4629-e190-984767f61d83"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(predictions, axis=1)"
      ],
      "metadata": {
        "id": "DQdQurWQ-6rF"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Syh-rZC8_FwG",
        "outputId": "e4019a76-c2db-43b1-d03c-3b5469cf258c"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([91])"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SerZoh3Y_IMW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}